# -*- coding: utf-8 -*-
"""answer_sheet_streamlit.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1i6FwH_fT0-6X4uYq9cZzJ8e1k7p8hR3P
"""

import streamlit as st
import os
import torch
import cv2
import numpy as np
from ultralytics import YOLO
from PIL import Image
from torchvision import transforms
import torch.nn as nn
from streamlit_webrtc import webrtc_streamer, WebRtcMode, RTCConfiguration
import av
import uuid
import time
from streamlit_option_menu import option_menu
from streamlit_image_comparison import image_comparison
from datetime import datetime
import json

# Set page configuration - Added theme='auto'
st.set_page_config(
    page_title="Smart Answer Sheet Scanner",
    page_icon="üìù",
    layout="wide",
    initial_sidebar_state="collapsed",
    # theme="auto" # This line enables automatic theme detection - Uncomment if needed, but config needs theme argument
    # Let's configure the theme directly in set_page_config if supported, otherwise rely on Streamlit defaults
    # Note: As of Streamlit 1.18, theme settings are done via config.toml or command line.
    # We will rely on removing hardcoded colors to allow default themes to work.
    # If using a newer Streamlit version that supports theme in set_page_config, uncomment the line above.
)

# Custom CSS for styling - Adjusted for theme compatibility
def local_css():
    # Removed hardcoded colors for better theme compatibility
    # Using Streamlit's theme variables where appropriate might be needed for finer control,
    # but removing conflicting hardcoded colors is the first step.
    st.markdown("""
    <style>
        /* Let Streamlit handle the main background and text colors */
        /* Removed .main background-color and color */
        /* Removed .stApp color */

        .stApp {
            max-width: 1200px;
            margin: 0 auto;
        }

        /* Removed default color override for common elements to allow theme inheritance */
        /* h1, h2, h3, h4, h5, h6, p, div, span, li, a {
            color: #000000 !important;
        } */

        /* Keep header button hidden as in original user file */
        [data-testid="stHeader"] button {
            display: none !important;
        }

        /* Button styling - Use Streamlit defaults or theme variables */
        /* Removed hardcoded background/color for better theme adaptation */
        .stButton>button {
            /* background-color: #d3d3d3; */ /* Light gray background - Removed */
            /* color: white; */ /* Removed - Let theme decide */
            font-weight: bold;
            border-radius: 10px;
            padding: 0.5rem 1rem;
            /* border: none; */ /* Consider keeping or removing based on desired look */
            transition: all 0.3s;
            cursor: pointer;
            display: inline-flex;
            align-items: center;
            justify-content: center;
            gap: 8px;
            width: 100%; /* Keep if full-width buttons are desired */
        }
        /* Removed hover style relying on hardcoded colors */
        /* .stButton>button:hover {
            background-color: #b0b0b0;
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
            transform: translateY(-2px);
        } */

        /* Active/Focus state - Consider using theme's primary color */
        .stButton>button:active, .stButton>button:focus {
             /* background-color: #4CAF50 !important; */ /* Green when clicked - Removed, use theme default or primary */
             /* Consider outline or other focus indicators */
        }

        /* Status boxes - Kept original colors, may need adjustment for dark theme contrast */
        .success-box {
            background-color: #d4edda;
            border-color: #c3e6cb;
            color: #155724 !important; /* High contrast needed */
            padding: 1rem;
            border-radius: 0.25rem;
            margin-bottom: 1rem;
        }
        .error-box {
            background-color: #f8d7da;
            border-color: #f5c6cb;
            color: #721c24 !important; /* High contrast needed */
            padding: 1rem;
            border-radius: 0.25rem;
            margin-bottom: 1rem;
        }
        .info-box {
            background-color: #cce5ff;
            border-color: #b8daff;
            color: #004085 !important; /* High contrast needed */
            padding: 1rem;
            border-radius: 0.25rem;
            margin-bottom: 1rem;
        }
        .warning-box { /* Renamed from inline style for consistency */
            background-color: #fff3cd;
            border-color: #ffeeba;
            color: #856404 !important; /* High contrast needed */
            padding: 1rem;
            border-radius: 0.25rem;
            margin-bottom: 1rem;
        }


        /* Result card - Use theme background or secondary background */
        .result-card {
            /* background-color: white; */ /* Removed - Use theme default */
            background-color: var(--secondary-background-color); /* Example using theme variable */
            border-radius: 10px;
            padding: 20px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            margin-bottom: 20px;
        }

        /* Header container - Gradient might clash with themes. Consider simpler background or theme colors */
        /* Removed forced white text color inside header */
        .header-container {
            background: linear-gradient(90deg, #4b6cb7 0%, #182848 100%); /* Kept gradient, might need theme-specific versions */
            padding: 20px;
            border-radius: 10px;
            /* color: white !important; */ /* Removed */
            margin-bottom: 30px;
        }
        .header-container h1, .header-container p {
             /* color: white !important; */ /* Removed - let theme handle text color */
             color: var(--text-color-inverse); /* Example: Use inverse text color on dark background */
        }

        /* Camera container - Use theme background */
        .camera-container {
            border: 2px dashed #ccc; /* Dashed border color might need theme adjustment */
            border-radius: 10px;
            padding: 10px;
            /* background-color: #f8f9fa; */ /* Removed */
            background-color: var(--secondary-background-color); /* Example */
        }

        .image-container {
            border-radius: 10px;
            overflow: hidden;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }

        /* Tab content - Use theme background */
        .tab-content {
            padding: 20px;
            border-radius: 0 0 10px 10px; /* Keep radius if desired */
            /* background-color: white; */ /* Removed */
            background-color: var(--background-color); /* Example */
            box-shadow: 0 4px 6px rgba(0,0,0,0.1); /* Shadow might need theme adjustment */
        }

        /* History item - Use theme background and text color */
        .history-item {
            padding: 15px;
            border-radius: 8px;
            margin-bottom: 15px;
            /* background-color: #f1f1f1; */ /* Removed */
            background-color: var(--secondary-background-color); /* Example */
            cursor: pointer;
            transition: all 0.3s;
            border-left: 5px solid var(--primary-color); /* Use theme primary color */
        }
        /* History item hover - Adjust based on theme */
        .history-item:hover {
            /* background-color: #e1e1e1; */ /* Removed */
            /* Use a slightly different shade of secondary background or add border/shadow */
            filter: brightness(95%); /* Example adjustment */
            transform: translateY(-2px);
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        /* History item text - Inherit theme text color */
        .history-item p {
            margin: 5px 0;
            /* color: #333 !important; */ /* Removed */
        }

        /* Footer - Adjust background and text for theme */
        .footer {
            margin-top: 50px;
            padding: 20px;
            text-align: center;
            /* color: #333333 !important; */ /* Removed */
            font-size: 0.9rem;
            /* background-color: #e9ecef; */ /* Removed */
            background-color: var(--secondary-background-color); /* Example */
            border-radius: 10px;
            box-shadow: 0 -2px 4px rgba(0,0,0,0.05);
            width: 100%;
        }
        .footer p {
            margin: 5px 0;
            /* color: #333333 !important; */ /* Removed */
        }
        /* Footer link - Use theme primary color */
        .footer a {
            /* color: #4CAF50 !important; */ /* Removed */
            color: var(--primary-color) !important; /* Example */
            text-decoration: none;
            transition: color 0.3s;
        }
        .footer a:hover {
            /* color: #388E3C !important; */ /* Removed */
            /* Slightly darken primary color or use default hover */
            filter: brightness(85%); /* Example */
            text-decoration: underline;
        }
        .footer-content {
            max-width: 1200px;
            margin: 0 auto;
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 10px;
        }
        /* Media queries for footer kept as is */
        @media (max-width: 768px) {
            .footer { padding: 15px; font-size: 0.8rem; }
            .footer-content { flex-direction: column; gap: 8px; }
        }
        @media (max-width: 480px) {
            .footer { padding: 10px; font-size: 0.7rem; }
            .footer-content { gap: 6px; }
        }

        .camera-controls {
            display: flex;
            justify-content: center;
            gap: 20px;
            margin-top: 10px;
        }
        /* Progress bar - Use theme primary color */
        .stProgress > div > div > div > div {
            /* background-color: #4CAF50 !important; */ /* Removed */
            background-color: var(--primary-color) !important; /* Example */
        }
        .input-buttons-col {
            display: flex;
            flex-direction: column;
            gap: 10px;
            margin-bottom: 20px;
            max-width: 200px;
            margin-left: auto;
            margin-right: auto;
        }
        /* Extracted output box - Adjust background/border for theme */
        .extracted-output {
            /* background-color: #e6f3ff; */ /* Removed */
            background-color: var(--secondary-background-color); /* Example */
            /* border: 2px solid #4CAF50; */ /* Removed */
            border: 2px solid var(--primary-color); /* Example */
            border-radius: 10px;
            padding: 15px;
            margin-top: 20px;
            font-family: 'Courier New', Courier, monospace;
            /* Ensure text color is readable */
            color: var(--text-color);
        }
    </style>
    """, unsafe_allow_html=True)

local_css()

# Initialize session state (same as before)
if 'image_path' not in st.session_state:
    st.session_state.image_path = None
if 'image_captured' not in st.session_state:
    st.session_state.image_captured = False
if 'results_history' not in st.session_state:
    st.session_state.results_history = []
if 'processing_start_time' not in st.session_state:
    st.session_state.processing_start_time = None
if 'selected_history_item' not in st.session_state:
    st.session_state.selected_history_item = None
if 'webrtc_key' not in st.session_state:
    st.session_state.webrtc_key = uuid.uuid4().hex
if 'input_method' not in st.session_state:
    st.session_state.input_method = "Upload Image"

# Define CRNN model (same as before)
class CRNN(nn.Module):
    def __init__(self, num_classes):
        super(CRNN, self).__init__()
        self.cnn = nn.Sequential(
            nn.Conv2d(1, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),
            nn.Dropout2d(0.3),
            nn.Conv2d(128, 256, kernel_size=3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(),
            nn.Conv2d(256, 256, kernel_size=3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(),
            nn.MaxPool2d((2, 1), (2, 1)),
            nn.Conv2d(256, 512, kernel_size=3, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(),
            nn.Conv2d(512, 512, kernel_size=3, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(),
            nn.MaxPool2d((2, 1), (2, 1)),
            nn.Dropout2d(0.3),
            nn.Conv2d(512, 512, kernel_size=(2, 1)),
            nn.BatchNorm2d(512),
            nn.ReLU(),
        )
        self.rnn = nn.LSTM(512, 256, num_layers=2, bidirectional=True, dropout=0.3)
        self.dropout = nn.Dropout(0.5)
        self.fc = nn.Linear(512, num_classes)

    def forward(self, x):
        x = self.cnn(x)
        x = x.squeeze(2)
        x = x.permute(2, 0, 1)
        x, _ = self.rnn(x)
        x = self.dropout(x)
        x = self.fc(x)
        return x

# Cache model loading (same as before)
@st.cache_resource
def load_extractor():
    try:
        # Ensure model paths are correct relative to where the script is run
        script_dir = os.path.dirname(os.path.abspath(__file__)) if "__file__" in locals() else "."
        yolo_path = os.path.join(script_dir, "improved_weights.pt")
        register_crnn_path = os.path.join(script_dir, "best_crnn_model.pth")
        subject_crnn_path = os.path.join(script_dir, "best_subject_code_model.pth")

        # Create dummy files if they don't exist for demonstration purposes
        # REMOVE THIS BLOCK if you have the actual model files
        for p in [yolo_path, register_crnn_path, subject_crnn_path]:
             if not os.path.exists(p):
                 print(f"Warning: Model file {p} not found. Creating dummy file.")
                 # Create minimal dummy files (e.g., empty text file or minimal torch save)
                 # This won't work for actual inference but allows the app structure to load.
                 if p.endswith('.pt'): # YOLO
                     # Create a dummy YOLOv8 structure if possible, otherwise just a placeholder
                     try:
                       # A minimal dummy state dict might avoid immediate errors
                       dummy_state = {'model': torch.nn.Module()}
                       torch.save(dummy_state, p)
                     except Exception:
                       open(p, 'a').close() # Simple empty file as fallback
                 elif p.endswith('.pth'): # CRNN
                     # Save a minimal state dict for the CRNN structure
                     try:
                         dummy_model = CRNN(num_classes=11 if 'register' in p else 37) # Adjust num_classes
                         dummy_state = {'model_state_dict': dummy_model.state_dict()}
                         torch.save(dummy_state, p)
                     except Exception as e:
                          print(f"Error creating dummy .pth: {e}")
                          open(p, 'a').close() # Simple empty file as fallback

        # --- End of Dummy File Creation Block ---

        extractor = AnswerSheetExtractor(
            yolo_path,
            register_crnn_path,
            subject_crnn_path
        )
        return extractor
    except Exception as e:
        st.error(f"Failed to initialize extractor: {e}")
        st.info("Ensure model files (improved_weights.pt, best_crnn_model.pth, best_subject_code_model.pth) are present in the script's directory.")
        return None

# AnswerSheetExtractor class (modified paths slightly for clarity)
class AnswerSheetExtractor:
    def __init__(self, yolo_weights_path, register_crnn_model_path, subject_crnn_model_path):
        # Ensure directories exist relative to the script location
        script_dir = os.path.dirname(os.path.abspath(__file__)) if "__file__" in locals() else "."
        for dir_name in ["cropped_register_numbers", "cropped_subject_codes", "results", "uploads", "captures"]:
            dir_path = os.path.join(script_dir, dir_name)
            os.makedirs(dir_path, exist_ok=True)
        self.script_dir = script_dir # Store script directory

        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        st.info(f"Using device: {self.device}") # Log device usage

        if not os.path.exists(yolo_weights_path):
            raise FileNotFoundError(f"YOLO weights not found at: {yolo_weights_path}")
        try:
            # Load YOLO model
            self.yolo_model = YOLO(yolo_weights_path)
        except Exception as e:
            raise RuntimeError(f"Failed to load YOLO model from {yolo_weights_path}: {e}")

        # Load Register CRNN model
        self.register_crnn_model = CRNN(num_classes=11) # Digits 0-9 + blank
        self.register_crnn_model.to(self.device)
        if not os.path.exists(register_crnn_model_path):
            raise FileNotFoundError(f"Register CRNN model not found at: {register_crnn_model_path}")
        try:
            checkpoint = torch.load(register_crnn_model_path, map_location=self.device)
            # Handle potential differences in checkpoint structure
            if 'model_state_dict' in checkpoint:
                self.register_crnn_model.load_state_dict(checkpoint['model_state_dict'])
            elif 'state_dict' in checkpoint:
                 self.register_crnn_model.load_state_dict(checkpoint['state_dict'])
            else:
                 self.register_crnn_model.load_state_dict(checkpoint) # Assume checkpoint is the state_dict
        except Exception as e:
            raise RuntimeError(f"Failed to load register CRNN model state_dict from {register_crnn_model_path}: {e}")
        self.register_crnn_model.eval()

        # Load Subject CRNN model
        self.subject_crnn_model = CRNN(num_classes=37) # Digits 0-9 + Letters A-Z + blank
        self.subject_crnn_model.to(self.device)
        if not os.path.exists(subject_crnn_model_path):
            raise FileNotFoundError(f"Subject CRNN model not found at: {subject_crnn_model_path}")
        try:
             checkpoint = torch.load(subject_crnn_model_path, map_location=self.device)
             if 'model_state_dict' in checkpoint:
                 self.subject_crnn_model.load_state_dict(checkpoint['model_state_dict'])
             elif 'state_dict' in checkpoint:
                 self.subject_crnn_model.load_state_dict(checkpoint['state_dict'])
             else:
                 self.subject_crnn_model.load_state_dict(checkpoint)
        except Exception as e:
            raise RuntimeError(f"Failed to load subject CRNN model state_dict from {subject_crnn_model_path}: {e}")
        self.subject_crnn_model.eval()

        # Transforms (same as before)
        self.register_transform = transforms.Compose([
            transforms.Grayscale(num_output_channels=1),
            transforms.Resize((32, 256)), # Adjusted size based on typical register number aspect ratio
            transforms.ToTensor(),
            transforms.Normalize((0.5,), (0.5,))
        ])
        self.subject_transform = transforms.Compose([
            transforms.Grayscale(num_output_channels=1),
            transforms.Resize((32, 128)), # Adjusted size based on typical subject code aspect ratio
            transforms.ToTensor(),
            transforms.Normalize((0.5,), (0.5,))
        ])

        # Character Maps (same as before)
        # Register Map: 0=blank, 1='0', 2='1', ..., 10='9'
        self.register_char_map = {0: '', **{i: str(i-1) for i in range(1, 11)}}
        # Subject Map: 0=blank, 1='0', ..., 10='9', 11='A', ..., 36='Z'
        self.subject_char_map = {0: '', **{i: str(i-1) for i in range(1, 11)}, **{i: chr(i - 11 + ord('A')) for i in range(11, 37)}}


    def detect_regions(self, image_path):
        image = cv2.imread(image_path)
        if image is None:
            st.error(f"Could not load image from {image_path}")
            return [], [], None

        try:
            results = self.yolo_model(image) # Perform detection
        except Exception as e:
            st.error(f"Error during YOLO detection: {e}")
            return [], [], None

        detections = results[0].boxes
        classes = results[0].names # Get class names mapping

        register_regions = []
        subject_regions = []
        overlay = image.copy() # Create a copy for drawing overlays

        for box in detections:
            # Extract bounding box coordinates, confidence, and class ID
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            confidence = float(box.conf[0])
            class_id = int(box.cls[0])
            label = classes[class_id] # Get the class label string

            # Ensure coordinates are within image bounds
            h, w = image.shape[:2]
            x1, y1, x2, y2 = max(0, x1), max(0, y1), min(w, x2), min(h, y2)

            # Skip invalid boxes
            if x1 >= x2 or y1 >= y2:
                continue

            # Draw bounding box and label on the overlay image
            color = (0, 255, 0) if label == "RegisterNumber" else (0, 0, 255) if label == "SubjectCode" else (255, 0, 0) # Green for Register, Blue for Subject
            cv2.rectangle(overlay, (x1, y1), (x2, y2), color, 2)
            text_y = y1 - 10 if y1 > 20 else y1 + 20 # Position label above or below box
            cv2.putText(overlay, f"{label} {confidence:.2f}", (x1, text_y),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

            # Crop detected regions with padding and save them
            padding = 10 # Add padding around the detected box
            padded_x1, padded_y1 = max(0, x1 - padding), max(0, y1 - padding)
            padded_x2, padded_y2 = min(w, x2 + padding), min(h, y2 + padding)
            cropped_region = image[padded_y1:padded_y2, padded_x1:padded_x2]

            # Save cropped images to respective directories
            if label == "RegisterNumber" and confidence > 0.2: # Confidence threshold
                save_dir = os.path.join(self.script_dir, "cropped_register_numbers")
                save_path = os.path.join(save_dir, f"register_number_{uuid.uuid4().hex}.jpg")
                cv2.imwrite(save_path, cropped_region)
                register_regions.append((save_path, confidence))
            elif label == "SubjectCode" and confidence > 0.2: # Confidence threshold
                save_dir = os.path.join(self.script_dir, "cropped_subject_codes")
                save_path = os.path.join(save_dir, f"subject_code_{uuid.uuid4().hex}.jpg")
                cv2.imwrite(save_path, cropped_region)
                subject_regions.append((save_path, confidence))

        # Save the overlay image with detections
        overlay_dir = os.path.join(self.script_dir, "results")
        overlay_path = os.path.join(overlay_dir, f"detection_overlay_{uuid.uuid4().hex}.jpg")
        cv2.imwrite(overlay_path, overlay)

        return register_regions, subject_regions, overlay_path

    def extract_text(self, image_path, model, img_transform, char_map):
        try:
            if not os.path.exists(image_path):
                st.error(f"Cropped image not found: {image_path}")
                return "FILE_MISSING"

            # Open image, convert to grayscale, apply transforms
            image = Image.open(image_path).convert('L')
            image_tensor = img_transform(image).unsqueeze(0).to(self.device)

            # Perform inference with CRNN model
            with torch.no_grad():
                output = model(image_tensor) # Shape: (seq_len, batch_size, num_classes)
                # Permute to (batch_size, seq_len, num_classes) if needed by softmax/argmax, but CRNN output might be different
                # Check the output shape if errors occur. Assuming (seq_len, batch=1, num_classes)
                output = output.squeeze(1) # Remove batch dim if it's 1: (seq_len, num_classes)
                # Get the class index with the highest probability for each time step
                output = output.softmax(1).argmax(1)
                # Convert indices to numpy array
                seq = output.cpu().numpy()

            # Decode the sequence (CTC decoding logic)
            prev = 0
            result = []
            for s in seq:
                if s != 0 and s != prev: # Ignore blank (0) and consecutive duplicates
                    result.append(char_map.get(s, '?')) # Map index to character, '?' for unknown
                prev = s
            return ''.join(result)

        except Exception as e:
            st.error(f"Failed to extract text from {image_path}: {e}")
            return "ERROR"

    # Wrapper methods for register number and subject code extraction
    def extract_register_number(self, image_path):
        return self.extract_text(image_path, self.register_crnn_model, self.register_transform, self.register_char_map)

    def extract_subject_code(self, image_path):
        return self.extract_text(image_path, self.subject_crnn_model, self.subject_transform, self.subject_char_map)


    # Main processing function
    def process_answer_sheet(self, image_path):
        st.session_state.processing_start_time = time.time()

        # Step 1: Detect regions using YOLO
        with st.spinner("Detecting regions..."):
            register_regions, subject_regions, overlay_path = self.detect_regions(image_path)

        results = []
        best_register_cropped_path = None
        best_subject_cropped_path = None

        # Step 2: Extract Register Number from the best detection
        if register_regions:
            # Sort by confidence and pick the best one
            register_regions.sort(key=lambda x: x[1], reverse=True)
            best_region_path, best_confidence = register_regions[0]
            best_register_cropped_path = best_region_path
            with st.spinner("Extracting Register Number..."):
                register_number = self.extract_register_number(best_register_cropped_path)
            results.append(("Register Number", register_number))
            st_success(f"Register Number detected (Confidence: {best_confidence:.2f}). Extracted: '{register_number}'")
        else:
            st_warning("No RegisterNumber regions detected.") # Use warning box

        # Step 3: Extract Subject Code from the best detection
        if subject_regions:
            # Sort by confidence and pick the best one
            subject_regions.sort(key=lambda x: x[1], reverse=True)
            best_subject_path, best_confidence = subject_regions[0]
            best_subject_cropped_path = best_subject_path
            with st.spinner("Extracting Subject Code..."):
                subject_code = self.extract_subject_code(best_subject_cropped_path)
            results.append(("Subject Code", subject_code))
            st_success(f"Subject Code detected (Confidence: {best_confidence:.2f}). Extracted: '{subject_code}'")
        else:
            st_warning("No SubjectCode regions detected.") # Use warning box

        processing_time = time.time() - st.session_state.processing_start_time

        # Step 4: Store results in history
        if results or overlay_path: # Store even if only overlay exists
            history_item = {
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "original_image_path": image_path, # Keep path to original uploaded/captured image
                "overlay_image_path": overlay_path,
                "register_cropped_path": best_register_cropped_path,
                "subject_cropped_path": best_subject_cropped_path,
                "results": results,
                "processing_time": processing_time
            }
            # Prepend to history list so newest appears first
            st.session_state.results_history.insert(0, history_item)

        return results, best_register_cropped_path, best_subject_cropped_path, overlay_path, processing_time


# WebRTC configuration (same as before)
RTC_CONFIGURATION = RTCConfiguration(
    {"iceServers": [
        {"urls": ["stun:stun.l.google.com:19302"]},
        {"urls": ["stun:stun1.l.google.com:19302"]}
    ]}
)

# Video processor class (same as before)
class VideoProcessor:
    def __init__(self):
        self.frame = None
        self.last_frame_time = time.time()
        self.fps = 0
        self.frame_count = 0
        self.last_processed = 0
        self.process_interval = 0.1 # Process frame every 100ms

    def recv(self, frame: av.VideoFrame) -> av.VideoFrame:
        current_time = time.time()
        # Throttle processing to avoid overwhelming resources
        if current_time - self.last_processed < self.process_interval:
             # Return the last processed frame if available, otherwise the current frame
            return av.VideoFrame.from_ndarray(self.frame, format="bgr24") if self.frame is not None else frame

        img = frame.to_ndarray(format="bgr24")
        self.frame = img # Store the latest frame
        self.last_processed = current_time

        # Calculate FPS
        self.frame_count += 1
        if current_time - self.last_frame_time >= 1.0:
            self.fps = self.frame_count / (current_time - self.last_frame_time)
            self.last_frame_time = current_time
            self.frame_count = 0

        # Add overlays (FPS, aiming reticle, status text)
        cv2.putText(self.frame, f"FPS: {self.fps:.1f}", (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2) # Larger FPS text
        h, w = self.frame.shape[:2]
        center_x, center_y = w//2, h//2
        # Draw a simple red crosshair
        cv2.line(self.frame, (center_x - 15, center_y), (center_x + 15, center_y), (0, 0, 255), 2)
        cv2.line(self.frame, (center_x, center_y - 15), (center_x, center_y + 15), (0, 0, 255), 2)
        cv2.putText(self.frame, "Align Sheet & Capture", (center_x - 100, h - 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2) # Yellow text

        # Return the processed frame
        return av.VideoFrame.from_ndarray(self.frame, format="bgr24")


# Colored text boxes using CSS classes defined in local_css
def st_success(text):
    st.markdown(f'<div class="success-box">{text}</div>', unsafe_allow_html=True)

def st_error(text):
    st.markdown(f'<div class="error-box">{text}</div>', unsafe_allow_html=True)

def st_info(text):
    st.markdown(f'<div class="info-box">{text}</div>', unsafe_allow_html=True)

def st_warning(text):
    # Using the warning-box class defined in CSS
    st.markdown(f'<div class="warning-box">{text}</div>', unsafe_allow_html=True)


# Header display (same structure, text color now handled by theme/CSS)
def display_header():
    with st.container():
        st.markdown('<div class="header-container">', unsafe_allow_html=True)
        col1, col2 = st.columns([1, 5])
        with col1:
             # Using a different icon source/style for potential theme compatibility
             # st.image("https://img.icons8.com/ios-filled/100/ffffff/scanner.png", width=80)
             st.markdown('<div style="font-size: 60px; text-align: center;">üìù</div>', unsafe_allow_html=True) # Emoji as icon
        with col2:
            st.markdown('<h1>Smart Answer Sheet Scanner</h1>', unsafe_allow_html=True)
            st.markdown('<p>Automatically extract register numbers and subject codes</p>', unsafe_allow_html=True)
        st.markdown('</div>', unsafe_allow_html=True)

# Download button helper (same as before)
def get_image_download_button(image_path, filename, button_text):
    if image_path and os.path.exists(image_path):
        try:
            with open(image_path, "rb") as file:
                # Use a unique key to avoid conflicts when buttons reappear
                button_key = f"download_{filename.replace('.', '_')}_{uuid.uuid4().hex[:6]}"
                return st.download_button(
                    label=button_text,
                    data=file,
                    file_name=filename,
                    mime="image/jpeg", # Assuming JPG, adjust if needed
                    key=button_key
                )
        except Exception as e:
            st_error(f"Failed to create download button for {filename}: {e}")
    return None

# Save results helper (same as before)
def save_results_to_file(results, filename_prefix="results"):
    script_dir = os.path.dirname(os.path.abspath(__file__)) if "__file__" in locals() else "."
    results_dir = os.path.join(script_dir, "results")
    os.makedirs(results_dir, exist_ok=True) # Ensure results directory exists
    try:
        filename = f"{filename_prefix}_{uuid.uuid4().hex}.txt"
        filepath = os.path.join(results_dir, filename)
        with open(filepath, "w") as f:
            for label, value in results:
                f.write(f"{label}: {value}\n")
        return filepath
    except Exception as e:
        st_error(f"Failed to save results to {filepath}: {e}")
        return None

# --- Main App Logic ---
def main():
    display_header() # Show the custom header

    # Check for model files before loading
    script_dir = os.path.dirname(os.path.abspath(__file__)) if "__file__" in locals() else "."
    model_files = ["improved_weights.pt", "best_crnn_model.pth", "best_subject_code_model.pth"]
    model_paths = [os.path.join(script_dir, f) for f in model_files]

    # # Removed the check/stop here to allow dummy file creation in load_extractor for testing
    # if not all(os.path.exists(p) for p in model_paths):
    #     missing_files = [f for f, p in zip(model_files, model_paths) if not os.path.exists(p)]
    #     st_error("Missing model files: " + ", ".join(missing_files))
    #     st_info(f"Ensure model weights are in the script directory: {script_dir}")
    #     st.stop() # Stop execution if models are missing

    # Load the extractor (YOLO + CRNN models)
    with st.spinner("Loading models... This might take a moment."):
        extractor = load_extractor() # Calls the cached function
        if extractor:
            st_success("Models loaded successfully!")
        else:
            # Error handled within load_extractor, stop the app
            st.stop()

    # --- Navigation Tabs ---
    selected_tab = option_menu(
        menu_title=None, # No title for the menu bar
        options=["Scan", "History", "About"],
        icons=["camera", "clock-history", "info-circle"], # Icons for tabs
        default_index=0, # Start on the "Scan" tab
        orientation="horizontal",
        styles={
            # Use theme variables for better adaptation
            "container": {"padding": "0!important", "background-color": "var(--secondary-background-color)", "border-radius": "10px"},
            "icon": {"color": "var(--primary-color)", "font-size": "16px"}, # Use primary color for icons
            "nav-link": {
                "font-size": "16px",
                "text-align": "center",
                "margin": "0px",
                "padding": "10px",
                # "--hover-color": "#eee", # Remove hardcoded hover color
                "color": "var(--text-color)" # Use theme text color
            },
            "nav-link-selected": {"background-color": "var(--primary-color)", "color": "var(--text-color-inverse)"}, # Use theme primary color and inverse text
        }
    )

    # --- Scan Tab ---
    if selected_tab == "Scan":
        st.markdown('<div class="tab-content">', unsafe_allow_html=True)
        st.markdown("<h3>Choose input method:</h3>", unsafe_allow_html=True)

        # Input method selection buttons
        cols = st.columns(3) # Arrange buttons horizontally
        with cols[0]:
             if st.button("‚¨ÜÔ∏è Upload Image", key="upload_image_btn", use_container_width=True):
                 st.session_state.input_method = "Upload Image"
                 # Reset state when switching modes
                 st.session_state.image_path = None
                 st.session_state.image_captured = False
                 st.session_state.selected_history_item = None
                 st.rerun()
        with cols[1]:
             if st.button("üì∏ Use Camera", key="use_camera_btn", use_container_width=True):
                 st.session_state.input_method = "Use Camera"
                 # Reset state and camera key
                 st.session_state.image_path = None
                 st.session_state.image_captured = False
                 st.session_state.selected_history_item = None
                 st.session_state.webrtc_key = f"webrtc_{uuid.uuid4().hex}" # Ensure key changes
                 st.rerun()
        with cols[2]:
            if st.button("üîÑ Reset Scan", key="reset_btn_scan", use_container_width=True):
                # Clear all relevant session state variables
                st.session_state.image_path = None
                st.session_state.image_captured = False
                st.session_state.selected_history_item = None
                st.session_state.webrtc_key = f"webrtc_{uuid.uuid4().hex}" # Reset camera key
                st.session_state.input_method = "Upload Image" # Default back to upload
                # Clear history optionally? For now, keep history.
                # st.session_state.results_history = []
                st_info("Scan reset. Upload an image or use the camera.")
                st.rerun()

        st.markdown("---") # Separator

        # --- Image Upload Logic ---
        if st.session_state.input_method == "Upload Image":
            with st.container():
                st.markdown('<div class="camera-container" style="text-align: center;">', unsafe_allow_html=True) # Center content
                uploaded_file = st.file_uploader(
                    "Upload Answer Sheet Image",
                    type=["png", "jpg", "jpeg"],
                    key="uploader",
                    label_visibility="collapsed" # Hide label, use placeholder text
                )

                if uploaded_file:
                    # Save uploaded file temporarily
                    file_extension = uploaded_file.name.split('.')[-1].lower()
                    uploads_dir = os.path.join(script_dir, "uploads")
                    os.makedirs(uploads_dir, exist_ok=True)
                    temp_path = os.path.join(uploads_dir, f"image_{uuid.uuid4().hex}.{file_extension}")

                    try:
                        with open(temp_path, "wb") as f:
                            f.write(uploaded_file.getbuffer())
                        st.session_state.image_path = temp_path
                        st.session_state.image_captured = True # Mark as ready for processing
                        st.session_state.selected_history_item = None # Clear history selection
                        # Display the uploaded image
                        st.markdown('<div class="image-container">', unsafe_allow_html=True)
                        st.image(st.session_state.image_path, caption="Uploaded Image", use_container_width=True)
                        st.markdown('</div>', unsafe_allow_html=True)
                    except Exception as e:
                        st_error(f"Error saving uploaded file: {e}")
                        st.session_state.image_path = None
                        st.session_state.image_captured = False

                elif not st.session_state.image_path or not st.session_state.image_captured:
                     # Show placeholder if no image is uploaded/ready
                    st.markdown("""
                    <div style="border: 2px dashed #ccc; border-radius: 5px; padding: 40px 20px; margin-top: 10px;">
                        <h3>Drag & drop or click to upload</h3>
                        <p>Supported formats: JPG, PNG, JPEG</p>
                    </div>
                    """, unsafe_allow_html=True)
                st.markdown('</div>', unsafe_allow_html=True)

        # --- Camera Input Logic ---
        else: # Use Camera
            with st.container():
                st.markdown('<div class="camera-container">', unsafe_allow_html=True)
                if not st.session_state.image_captured:
                    # Display camera feed and controls only if image hasn't been captured yet
                    st.markdown("<h4>üì∏ Live Camera Feed</h4>", unsafe_allow_html=True)
                    st_info("Position the answer sheet within the frame and click 'Capture Image'.")

                    # Start WebRTC streamer
                    ctx = webrtc_streamer(
                        key=st.session_state.webrtc_key, # Use unique key from session state
                        mode=WebRtcMode.SENDRECV, # Send and receive video
                        rtc_configuration=RTC_CONFIGURATION, # Use STUN servers
                        media_stream_constraints={"video": {"width": 640, "height": 480}, "audio": False}, # Request video only
                        video_processor_factory=VideoProcessor, # Use custom processor for overlays
                        async_processing=True, # Process frames asynchronously
                    )

                    st.markdown('<div class="camera-controls">', unsafe_allow_html=True)
                    # Disable capture button if streamer is not running or frame not ready
                    capture_btn_disabled = not (ctx.state.playing and ctx.video_processor and hasattr(ctx.video_processor, 'frame') and ctx.video_processor.frame is not None)
                    if st.button("üì∏ Capture Image", key="capture_btn", disabled=capture_btn_disabled, use_container_width=True):
                        if not capture_btn_disabled:
                            frame_to_save = ctx.video_processor.frame
                            if frame_to_save is not None:
                                captures_dir = os.path.join(script_dir, "captures")
                                os.makedirs(captures_dir, exist_ok=True)
                                temp_path = os.path.join(captures_dir, f"image_{uuid.uuid4().hex}.jpg")
                                try:
                                    cv2.imwrite(temp_path, frame_to_save)
                                    if not os.path.exists(temp_path):
                                        raise IOError("Failed to save captured image file.")
                                    st.session_state.image_path = temp_path
                                    st.session_state.image_captured = True
                                    st.session_state.selected_history_item = None
                                    st_success("Image captured successfully!")
                                    # Stop the WebRTC stream gracefully if possible (might require context manager)
                                    # Rerun to show the captured image and processing button
                                    st.rerun()
                                except Exception as e:
                                    st_error(f"Error saving captured image: {e}")
                                    st.session_state.image_path = None
                                    st.session_state.image_captured = False
                            else:
                                st_warning("Could not get frame from camera. Try again.")
                        else:
                            st_warning("Camera not ready. Please wait for the feed to start.")

                    # # Add a restart button if needed, though changing mode usually restarts
                    # if st.button("üîÑ Restart Camera", key="restart_camera_btn"):
                    #     st.session_state.webrtc_key = f"webrtc_{uuid.uuid4().hex}" # Force remount
                    #     st.session_state.image_captured = False
                    #     st.session_state.image_path = None
                    #     st.rerun()
                    st.markdown('</div>', unsafe_allow_html=True)

                elif st.session_state.image_path and os.path.exists(st.session_state.image_path):
                    # If image has been captured, show it
                    st.markdown("<h4>Captured Image</h4>", unsafe_allow_html=True)
                    st.markdown('<div class="image-container">', unsafe_allow_html=True)
                    st.image(st.session_state.image_path, caption="Captured Image", use_container_width=True)
                    st.markdown('</div>', unsafe_allow_html=True)
                    # Add a button to recapture
                    if st.button("üîÑ Recapture Image", key="recapture_btn"):
                        st.session_state.image_captured = False
                        st.session_state.image_path = None
                        st.session_state.webrtc_key = f"webrtc_{uuid.uuid4().hex}" # Reset key
                        st.rerun()
                else:
                     # Handle case where image path exists in state but file doesn't
                     st_error("Captured image file seems to be missing. Please capture again.")
                     st.session_state.image_captured = False
                     st.session_state.image_path = None
                     if st.button("Go back to Camera", key="back_to_camera_btn"):
                         st.rerun()

                st.markdown('</div>', unsafe_allow_html=True) # End camera-container


        # --- Processing Logic (Common for Upload and Camera) ---
        if st.session_state.image_path and st.session_state.image_captured and st.session_state.selected_history_item is None:
            st.markdown("---") # Separator
            # Show the "Extract Information" button only when an image is ready and not viewing history
            if st.button("üîç Extract Information", key="extract_btn", type="primary", use_container_width=True):
                # Placeholder for status updates during processing
                status_placeholder = st.empty()
                status_placeholder.info("üöÄ Starting extraction process...")

                progress_bar = st.progress(0, text="Initializing...")

                try:
                    # --- Perform Extraction ---
                    # This function now handles spinners internally and updates history
                    results, register_cropped, subject_cropped, overlay_path, processing_time = extractor.process_answer_sheet(st.session_state.image_path)
                    progress_bar.progress(100, text="Extraction Complete!")
                    time.sleep(1) # Keep completion message visible briefly
                    progress_bar.empty() # Clear progress bar
                    status_placeholder.empty() # Clear status message

                    # Display results in a structured card
                    st.markdown('<div class="result-card">', unsafe_allow_html=True)
                    st.subheader("üìã Extracted Information")
                    if results:
                        # Display extracted values in the dedicated output box
                        st.markdown('<div class="extracted-output">', unsafe_allow_html=True)
                        for label, value in results:
                            st.markdown(f"**{label}:** `{value}`")
                        st.markdown('</div>', unsafe_allow_html=True)

                        # Provide download button for text results
                        results_file = save_results_to_file(results, f"results_{datetime.now().strftime('%Y%m%d%H%M%S')}")
                        if results_file and os.path.exists(results_file):
                            with open(results_file, "rb") as file:
                                st.download_button(
                                    label="üì• Download Results (.txt)",
                                    data=file,
                                    file_name="extracted_data.txt",
                                    mime="text/plain",
                                    key=f"download_results_{uuid.uuid4().hex}"
                                )
                        else:
                            st_warning("Could not save results to a file for download.")
                    else:
                        st_warning("Could not extract any information. Please check the image quality or model performance.") # Use warning box
                    st.markdown(f"<p style='text-align: right; font-size: 0.9em;'>Processing time: {processing_time:.2f} seconds</p>", unsafe_allow_html=True)
                    st.markdown('</div>', unsafe_allow_html=True) # End result-card

                    # --- Display Images (Comparison and Cropped) ---
                    st.subheader("üîç Visual Results")
                    img_cols = st.columns(2)
                    with img_cols[0]:
                         # Show Original vs. Detections comparison
                         st.markdown("<h6>Original vs. Detections</h6>", unsafe_allow_html=True)
                         if st.session_state.image_path and overlay_path and os.path.exists(st.session_state.image_path) and os.path.exists(overlay_path):
                             st.markdown('<div class="image-container">', unsafe_allow_html=True)
                             image_comparison(
                                 img1=st.session_state.image_path,
                                 img2=overlay_path,
                                 label1="Original",
                                 label2="Detections",
                                 use_container_width=True
                             )
                             st.markdown('</div>', unsafe_allow_html=True)
                             # Add download for overlay image
                             get_image_download_button(overlay_path, "detections_overlay.jpg", "Download Detections Image")
                         else:
                             st_warning("Could not display image comparison (original or overlay missing).")

                    with img_cols[1]:
                         # Show Cropped Regions if available
                         st.markdown("<h6>Cropped Regions</h6>", unsafe_allow_html=True)
                         if register_cropped and os.path.exists(register_cropped):
                             st.markdown('<div class="image-container" style="margin-bottom: 10px;">', unsafe_allow_html=True)
                             st.image(register_cropped, caption="Register Number", use_container_width=True)
                             st.markdown('</div>', unsafe_allow_html=True)
                             get_image_download_button(register_cropped, "register_number_crop.jpg", "Download Register Crop")
                         else:
                              st.markdown("<p>No Register Number crop.</p>", unsafe_allow_html=True)

                         if subject_cropped and os.path.exists(subject_cropped):
                             st.markdown('<div class="image-container" style="margin-bottom: 10px;">', unsafe_allow_html=True)
                             st.image(subject_cropped, caption="Subject Code", use_container_width=True)
                             st.markdown('</div>', unsafe_allow_html=True)
                             get_image_download_button(subject_cropped, "subject_code_crop.jpg", "Download Subject Crop")
                         else:
                              st.markdown("<p>No Subject Code crop.</p>", unsafe_allow_html=True)

                         if not register_cropped and not subject_cropped:
                            st_info("No regions were successfully cropped.")

                except FileNotFoundError as fnf_error:
                     progress_bar.empty()
                     status_placeholder.empty()
                     st_error(f"File Error: {fnf_error}")
                     st_info("Please ensure the image path is correct and the file exists.")
                except RuntimeError as rt_error:
                     progress_bar.empty()
                     status_placeholder.empty()
                     st_error(f"Model Runtime Error: {rt_error}")
                     st_info("This might be due to model loading issues or compatibility problems (e.g., CUDA). Check console logs.")
                except Exception as e:
                    # Catch any other unexpected errors during processing
                    progress_bar.empty()
                    status_placeholder.empty()
                    st_error(f"An unexpected error occurred during processing: {e}")
                    st_info("Please try again with a different image or check the application logs.")
                finally:
                    # Ensure placeholders are cleared even if errors occur
                     if 'status_placeholder' in locals() and hasattr(status_placeholder, 'empty'):
                         status_placeholder.empty()
                     if 'progress_bar' in locals() and hasattr(progress_bar, 'empty'):
                         progress_bar.empty()

        st.markdown('</div>', unsafe_allow_html=True) # End tab-content for Scan

    # --- History Tab ---
    elif selected_tab == "History":
        st.markdown('<div class="tab-content">', unsafe_allow_html=True)
        st.subheader("Ôáö Processing History")

        if not st.session_state.results_history:
            st_info("No processing history yet. Scan an answer sheet on the 'Scan' tab to populate history.")
        else:
             # Display summary of each history item
             st.markdown("Click 'View Details' to see the images and full results for a past scan.")
             for i, item in enumerate(st.session_state.results_history): # Iterate directly (newest first due to insert(0))
                 timestamp = item.get("timestamp", "N/A")
                 results_summary = ", ".join([f"{label}: `{value}`" for label, value in item.get("results", [])])
                 if not results_summary: results_summary = "N/A"
                 processing_time = item.get("processing_time", 0)

                 # Use columns for better layout
                 hist_cols = st.columns([3, 1])
                 with hist_cols[0]:
                     # Display item info in the history-item styled div
                     st.markdown(f"""
                     <div class="history-item">
                         <p><strong>Scan Time:</strong> {timestamp}</p>
                         <p><strong>Results:</strong> {results_summary}</p>
                         <p><strong>Processing Time:</strong> {processing_time:.2f} sec</p>
                     </div>
                     """, unsafe_allow_html=True)
                 with hist_cols[1]:
                     # Button to view details for this specific item
                     if st.button("View Details", key=f"view_history_{i}", use_container_width=True):
                         # Store the index or the item itself in session state
                         st.session_state.selected_history_item_index = i
                         st.rerun() # Rerun to display the detailed view

             st.markdown("---")

             # --- Detailed History View ---
             if 'selected_history_item_index' in st.session_state and st.session_state.selected_history_item_index is not None:
                 st.subheader("üìú Detailed History View")
                 try:
                    selected_item = st.session_state.results_history[st.session_state.selected_history_item_index]
                 except IndexError:
                      st_error("Selected history item not found. It might have been cleared.")
                      st.session_state.selected_history_item_index = None # Reset index
                      st.rerun()

                 # Display details from the selected history item
                 st.markdown('<div class="result-card">', unsafe_allow_html=True)
                 st.markdown(f"<h6>Scan Timestamp: {selected_item.get('timestamp', 'N/A')}</h6>", unsafe_allow_html=True)
                 st.markdown(f"<p>Processing Time: {selected_item.get('processing_time', 0):.2f} seconds</p>", unsafe_allow_html=True)

                 st.markdown("<h6>Extracted Information:</h6>", unsafe_allow_html=True)
                 if selected_item.get("results"):
                     st.markdown('<div class="extracted-output">', unsafe_allow_html=True)
                     for label, value in selected_item["results"]:
                         st.markdown(f"**{label}:** `{value}`")
                     st.markdown('</div>', unsafe_allow_html=True)
                 else:
                     st_info("No results were extracted in this scan.")
                 st.markdown('</div>', unsafe_allow_html=True) # End result-card

                 # Display Images from History
                 st.markdown("<h6>Images from Scan:</h6>", unsafe_allow_html=True)
                 hist_img_cols = st.columns(2)
                 original_image_path = selected_item.get("original_image_path")
                 overlay_image_path = selected_item.get("overlay_image_path")
                 register_cropped_path = selected_item.get("register_cropped_path")
                 subject_cropped_path = selected_item.get("subject_cropped_path")

                 with hist_img_cols[0]:
                    st.markdown("<u>Original vs. Detections:</u>", unsafe_allow_html=True)
                    if original_image_path and overlay_image_path and os.path.exists(original_image_path) and os.path.exists(overlay_image_path):
                        st.markdown('<div class="image-container">', unsafe_allow_html=True)
                        image_comparison(
                            img1=original_image_path, img2=overlay_image_path,
                            label1="Original", label2="Detections", use_container_width=True
                            )
                        st.markdown('</div>', unsafe_allow_html=True)
                    else:
                         st_warning("Original or detection overlay image not found for this history item.")

                 with hist_img_cols[1]:
                     st.markdown("<u>Cropped Regions:</u>", unsafe_allow_html=True)
                     if register_cropped_path and os.path.exists(register_cropped_path):
                         st.markdown('<div class="image-container" style="margin-bottom: 10px;">', unsafe_allow_html=True)
                         st.image(register_cropped_path, caption="Register Number (Cropped)", use_container_width=True)
                         st.markdown('</div>', unsafe_allow_html=True)
                     else:
                          st.markdown("<p>No Register Number crop.</p>", unsafe_allow_html=True)

                     if subject_cropped_path and os.path.exists(subject_cropped_path):
                          st.markdown('<div class="image-container" style="margin-bottom: 10px;">', unsafe_allow_html=True)
                          st.image(subject_cropped_path, caption="Subject Code (Cropped)", use_container_width=True)
                          st.markdown('</div>', unsafe_allow_html=True)
                     else:
                           st.markdown("<p>No Subject Code crop.</p>", unsafe_allow_html=True)


                 # Button to go back to the history list view
                 if st.button("Hide Details", key="hide_history_details"):
                    st.session_state.selected_history_item_index = None
                    st.rerun()


        st.markdown('</div>', unsafe_allow_html=True) # End tab-content for History


    # --- About Tab ---
    elif selected_tab == "About":
        st.markdown('<div class="tab-content">', unsafe_allow_html=True)
        st.subheader("‚ÑπÔ∏è About the Smart Answer Sheet Scanner")

        col_about1, col_about2 = st.columns([1, 3]) # Adjust column ratio
        with col_about1:
            # Use a theme-friendly icon or image placeholder
            st.markdown('<div style="font-size: 100px; text-align: center; padding-top: 20px;">üßê</div>', unsafe_allow_html=True) # Emoji
        with col_about2:
            st.markdown("""
            <p>This application leverages computer vision models to automatically detect and extract Register Numbers and Subject Codes from scanned or photographed answer sheets.</p>
            <h6>Key Technologies Used:</h6>
            <ul>
                <li><b>Object Detection:</b> A custom-trained YOLOv8 model identifies the locations of the relevant fields (Register Number, Subject Code) on the sheet.</li>
                <li><b>Text Recognition (OCR):</b> Convolutional Recurrent Neural Network (CRNN) models are employed to read the characters within the detected regions. Separate CRNN models are optimized for recognizing digits (Register Number) and alphanumeric characters (Subject Code).</li>
                <li><b>Web Interface:</b> Built with Streamlit, providing an interactive user interface for image upload, camera capture, and results visualization.</li>
            </ul>
            """, unsafe_allow_html=True)

        st.markdown("---")
        st.markdown("<h6>How to Use:</h6>", unsafe_allow_html=True)
        st.markdown("""
        <ol>
            <li>Navigate to the <b>Scan</b> tab.</li>
            <li>Choose your input method: <b>Upload Image</b> or <b>Use Camera</b>.</li>
            <li>If uploading, select a clear image of the answer sheet.</li>
            <li>If using the camera, position the sheet clearly in the frame and click <b>Capture Image</b>.</li>
            <li>Once an image is loaded or captured, click <b>Extract Information</b>.</li>
            <li>View the extracted text, detection overlays, and cropped regions.</li>
            <li>Check the <b>History</b> tab to review past scans.</li>
        </ol>
        """, unsafe_allow_html=True)

        st.markdown("---")
        st.markdown("<h6>Model Information:</h6>", unsafe_allow_html=True)
        st.markdown("""
        <ul>
            <li>The models require specific weights files (`improved_weights.pt`, `best_crnn_model.pth`, `best_subject_code_model.pth`) to be present in the same directory as the script.</li>
            <li>Accuracy is dependent on the quality of the input image (clarity, lighting, angle) and the training data used for the models.</li>
        </ul>
        """, unsafe_allow_html=True)

        st.markdown("---")
        st.markdown("<h6>Disclaimer:</h6>", unsafe_allow_html=True)
        st_warning("This tool is for demonstration or assistive purposes. Extracted results should always be verified for accuracy, especially in critical applications.") # Use warning box


        st.markdown('</div>', unsafe_allow_html=True) # End tab-content for About

    # --- Footer ---
    # Footer content is styled via CSS, structure remains simple
    st.markdown('<div class="footer">', unsafe_allow_html=True)
    st.markdown('<div class="footer-content">', unsafe_allow_html=True)
    st.markdown("<p>¬© 2024-2025 Smart Scanner Project. Built with Streamlit.</p>", unsafe_allow_html=True)
    # Add links or other info as needed
    # st.markdown("<p><a href='#' target='_blank'>Documentation</a> | <a href='#' target='_blank'>GitHub</a></p>", unsafe_allow_html=True)
    st.markdown('</div>', unsafe_allow_html=True)
    st.markdown('</div>', unsafe_allow_html=True)

# --- Entry Point ---
if __name__ == "__main__":
    main()